{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_image_size = 256, 256\n",
    "master_color_channels = 1\n",
    "random.seed(0)\n",
    "base_image_dir = 'grayscale-256x256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    \"\"\"\n",
    "    Creates a new CNN model. It also prints a summary of the\n",
    "    model.\n",
    "    \n",
    "    It uses the external variables master_image_size and\n",
    "    master_color_channels to setup the input layer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.models.Sequential\n",
    "        The model ready to be trained\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(master_image_size[0], master_image_size[1], master_color_channels)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=0.5e-4), metrics=['acc'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test(base_path, shuffle_seed=0):\n",
    "    \"\"\"\n",
    "    Reads images in a directory and splits them up according to class\n",
    "    \n",
    "    Assumes a binary classification, with EQUAL COUNTS in each\n",
    "    class.\n",
    "    \n",
    "    This automatically assigns classes to the images. It assumes\n",
    "    the name of each class is the first token of the filename as\n",
    "    delimited by \"_\".\n",
    "    \n",
    "    The dataframes returned are to be used by Keras. They have the\n",
    "    columns \"filename\" and \"class\" to point to the images and the\n",
    "    classes, repectively.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_path : str\n",
    "        The relative path to the images.\n",
    "        \n",
    "    shuffle_seed : int\n",
    "        The integer to seed the random number generator which shuffles\n",
    "        the dataframe.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame, pd.DataFrame, pd.DataFrame\n",
    "        The train, validation and test sets, respectively.\n",
    "    \"\"\"\n",
    "    print(f'>>> Shuffle seed {shuffle_seed}')\n",
    "    \n",
    "    train_fraction = 0.8\n",
    "    random.seed(shuffle_seed)\n",
    "    \n",
    "    all_images_list = []\n",
    "    \n",
    "    for filename in os.listdir(base_path):\n",
    "        if isfile(join(base_path, filename)):\n",
    "            image_class = filename.split('.')[0]\n",
    "            all_images_list.append({'class': image_class, 'filename': filename})\n",
    "    \n",
    "    all_images = pd.DataFrame(all_images_list)\n",
    "    all_images = all_images.sample(frac=1).reset_index(drop=True)\n",
    "    all_classes = all_images['class'].unique()\n",
    "    \n",
    "    first_class_name = all_classes[0]\n",
    "    second_class_name = all_classes[1]\n",
    "    \n",
    "    first_class = all_images.copy().where(all_images['class'] == first_class_name).dropna()\n",
    "    second_class = all_images.copy().where(all_images['class'] == second_class_name).dropna()\n",
    "\n",
    "    train_row_count = int(len(first_class) * train_fraction)\n",
    "    test_val_count = len(first_class) - train_row_count\n",
    "    \n",
    "    first_class_train = first_class.iloc[2 * test_val_count:]\n",
    "    first_class_val = first_class.iloc[test_val_count:2 * test_val_count]\n",
    "    first_class_test = first_class.iloc[0:test_val_count]\n",
    "    \n",
    "    second_class_train = second_class.iloc[2 * test_val_count:]\n",
    "    second_class_val = second_class.iloc[test_val_count:2 * test_val_count]\n",
    "    second_class_test = second_class.iloc[0:test_val_count]\n",
    "    \n",
    "    train = first_class_train.append(second_class_train).reset_index().drop('index', axis=1)\n",
    "    val = first_class_val.append(second_class_val).reset_index().drop('index', axis=1)\n",
    "    test = first_class_test.append(second_class_test).reset_index().drop('index', axis=1)\n",
    "    \n",
    "    print(first_class_name, second_class_name)\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_generators(src_dir, shuffle_seed=0):\n",
    "    \"\"\"\n",
    "    Creates generators for train, validation and test datasets. These\n",
    "    can then be used by Keras to train a model.\n",
    "    \n",
    "    Dataframe shuffling is prevented at this step because the dataframe\n",
    "    is assumed to have been shuffled beforehand with an RNG with a known\n",
    "    seed.\n",
    "    \n",
    "    The dataframe is created for you from the images in src_dir. See the\n",
    "    train_validation_test function for more information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src_dir : str\n",
    "        The relative path to the train, validation and test images\n",
    "        \n",
    "    shuffle_seed : int\n",
    "        The seed for the RNG used for dataframe shuffling.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    train, validation, test = train_validation_test(src_dir, shuffle_seed)\n",
    "\n",
    "    train_datagen = image.ImageDataGenerator(rescale=1.0/255)\n",
    "    test_datagen = image.ImageDataGenerator(rescale=1.0/255)\n",
    "    validation_datagen = image.ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(dataframe=train,\n",
    "                                                        directory=src_dir,\n",
    "                                                        target_size=master_image_size,\n",
    "                                                        batch_size=20,\n",
    "                                                        shuffle=False,\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_dataframe(dataframe=validation,\n",
    "                                                      directory=src_dir,\n",
    "                                                      target_size=master_image_size,\n",
    "                                                      batch_size=20,\n",
    "                                                      shuffle=False,\n",
    "                                                      color_mode='grayscale',\n",
    "                                                      class_mode='binary')\n",
    "\n",
    "    test_generator = train_datagen.flow_from_dataframe(dataframe=test,\n",
    "                                                       directory=src_dir,\n",
    "                                                       target_size=master_image_size,\n",
    "                                                       batch_size=20,\n",
    "                                                       shuffle=False,\n",
    "                                                       color_mode='grayscale',\n",
    "                                                       class_mode='binary')\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_get_history(base_image_dir, shuffle_seed=0, epochs=10):\n",
    "    \"\"\"\n",
    "    Trains a model and returns the RNG seed and history\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_image_dir : str\n",
    "        The relative path to the images.\n",
    "        \n",
    "    shuffle_seed : int\n",
    "        The seed for the RNG that shuffles the train, validation\n",
    "        and test datasets.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    keras.model.Sequential, dict\n",
    "        The model that created the history\n",
    "    \"\"\"\n",
    "    train_generator, validation_generator, test_generator = train_validation_test_generators(base_image_dir, shuffle_seed)\n",
    "    model = get_new_model()\n",
    "    train_history = model.fit_generator(train_generator,\n",
    "                                        steps_per_epoch=128,\n",
    "                                        epochs=epochs,\n",
    "                                        validation_data=validation_generator,\n",
    "                                        validation_steps=64,\n",
    "                                        verbose=1)\n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_run_different_shuffles(shuffles, src_image_dir, epochs_per_shuffle=10):\n",
    "    histories = []\n",
    "    for seed in range(shuffles):\n",
    "        model, history = train_model_and_get_history(src_image_dir, seed, epochs=epochs_per_shuffle)\n",
    "        histories.append({\n",
    "            'seed': seed,\n",
    "            'epochs': epochs_per_shuffle,\n",
    "            'history': history,\n",
    "            'model': model\n",
    "        })\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Shuffle seed 0\n",
      "benzene_ring non_benzene_ring\n",
      "Found 246 validated image filenames belonging to 2 classes.\n",
      "Found 82 validated image filenames belonging to 2 classes.\n",
      "Found 82 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/alicia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 128)     1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,290,113\n",
      "Trainable params: 13,290,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/alicia/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 38s 294ms/step - loss: 0.7272 - acc: 0.4620 - val_loss: 0.6955 - val_acc: 0.4991\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 33s 257ms/step - loss: 0.7111 - acc: 0.4845 - val_loss: 0.6846 - val_acc: 0.5277\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 33s 258ms/step - loss: 0.6720 - acc: 0.6424 - val_loss: 0.6325 - val_acc: 0.6377\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 33s 258ms/step - loss: 0.5419 - acc: 0.7577 - val_loss: 0.6986 - val_acc: 0.5813\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 33s 258ms/step - loss: 0.4296 - acc: 0.8218 - val_loss: 0.7030 - val_acc: 0.6931\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 33s 259ms/step - loss: 0.2781 - acc: 0.8871 - val_loss: 0.7252 - val_acc: 0.6711\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 33s 260ms/step - loss: 0.1197 - acc: 0.9672 - val_loss: 1.5588 - val_acc: 0.6291\n",
      "Epoch 8/10\n",
      " 32/128 [======>.......................] - ETA: 21s - loss: 0.0466 - acc: 0.9875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-31a6f911bb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_run_different_shuffles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_image_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_per_shuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-b911b9ec9341>\u001b[0m in \u001b[0;36mtrain_and_run_different_shuffles\u001b[0;34m(shuffles, src_image_dir, epochs_per_shuffle)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_and_get_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_per_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         histories.append({\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m'seed'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4c5f4601f558>\u001b[0m in \u001b[0;36mtrain_model_and_get_history\u001b[0;34m(base_image_dir, shuffle_seed, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                         verbose=1)\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = train_and_run_different_shuffles(2, src_image_dir=base_image_dir, epochs_per_shuffle=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
